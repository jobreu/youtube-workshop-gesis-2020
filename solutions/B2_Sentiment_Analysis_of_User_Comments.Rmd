---
title: 'Exercises - Sentiment Analysis for User Comments'
author: 'Julian Kohne'
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  unilur::tutorial_html_solution: default
  unilur::tutorial_pdf_solution: default
  unilur::tutorial_pdf: default
  unilur::tutorial_html: default
---

```{r knitr_init, echo=FALSE, cache=FALSE, include=FALSE}
# custom boxes
knitr::opts_template$set(clues = list(box.title = "Clues",
                                      box.body = list(fill = "#fff9dc", colour = "black"),
                                      box.header = list(fill = "#ffec8b", colour = "black"),
                                      box.icon = "fa-search",
                                      box.collapse = TRUE))

```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

In these exercises, we will be going through the dataset you preprocessed yesterday and perform three types of sentiment analysis:

1) Basic sentiment analysis of text
2) Slightly more elaborated sentiment analysis of text
3) Experimental sentiment analysis on emoji


```{block, box.title = "Exercise 1", box.body = list(fill = "white"), box.icon = "fa-star"}
Setup your R-session and load your data so that we can perform sentiment analysis. Assign the loaded data to a dataframe with the name `comments`.

```

```{block, opts.label = "clues"}
You should use the `options()` function to prevent R from interpreting your character variables as factor variables. If you are not sure how to use the `options()` you can always search it in Rstudios help panel and have a look at all the different options there are. After setting the options, you should load your preprocessed dataset with `readRDS()`. Don't forget to attach the necessary packages `syuzhet` and `sentimentr`.

```

```{r, results = 'hide', solution = TRUE, warning=F,message=F}
# Preventing R from inteprreting characters as factors
options(stringsAsFactors = FALSE)

# attaching packages
library(syuzhet)
library(sentimentr)

# Loading data
comments <- readRDS("../data/ParsedComments.rds")

```


```{block, box.title = "Exercise 2", box.body = list(fill = "white"), box.icon = "fa-star"}
Chose the appropriate column from your `comments` dataframe to perform a basic sentiment analysis on. Which columns are suitable and which are not? Save comment sentiments in a new variable called `BasicSentimentSyu` and check whether the column has any zero values. If there are zero values, why might this be the case?

```

```{block, opts.label = "clues"}
hyperlinks and emoji might cause Problems for sentiment analysis (or any textmining methods really). You can check whether a variable contains a given value x using the following approach `table(variable == x)` with your respective variable name.

```

```{r, solution = TRUE, warning=F,message=F}
# Creating new column
BasicSentimentSyu <- get_sentiment(comments$TextEmojiDeleted)

# checking zero values
table(BasicSentimentSyu == 0)

```

```{block, solution = TRUE}

Zero values are given to comments containing no words from the used dictionary or containing multiple words with sentiment scores that cancel each other out **exactly**.

```


```{block, box.title = "Exercise 3", box.body = list(fill = "white"), box.icon = "fa-star"}
Check the documentation of the `syuzhet` package and the `get_sentiment()` function to see which dictionaries are available. Create a correlation matrix for sentiment scores using the different methods (you can leave out stanford). Which factors might result in low correlations between the dictionaries? Which one is the best to use?
```

```{block, opts.label = "clues"}
You can find the documentation for the `get_sentiment()` function by searching for it's name in the Rstudio help panel or by entering `?get_sentiment()` in your console. You can also search online for further information. A correlation matrix can be created with the `cor` function. As this function needs a dataframe as an input, you need to create one variable for each sentiment dictionary rating and combine it into a dataframe with `cbind.data.frame()` before passing it to `cor`.

```

```{block, solution = TRUE}

Which [dictionary](https://arxiv.org/pdf/1901.08319) is best always depends on your research question and what kind of data you want to use. In general, you should pick a dictionary that is as similar to your data as possible and is most sensitive to the kind of sentiment that you are interested in (dictionaries sometimes contain mainly positive or mainly negative entries).

```


```{r, solution = TRUE, warning=F,message=F}
# computing sentiment scores with different dictionaries
BasicSentimentSyu <- get_sentiment(comments$TextEmojiDeleted,method = "syuzhet")
BasicSentimentBing <- get_sentiment(comments$TextEmojiDeleted,method = "bing")
BasicSentimentAfinn <- get_sentiment(comments$TextEmojiDeleted,method = "afinn")
BasicSentimentNRC <- get_sentiment(comments$TextEmojiDeleted,method = "nrc")

# combining them to a dataframe
Sentiments <- cbind.data.frame(BasicSentimentSyu,
                               BasicSentimentBing,
                               BasicSentimentAfinn,
                               BasicSentimentNRC)
# setting colnames
colnames(Sentiments) <- c("Syuzhet",
                          "Bing",
                          "Afinn",
                          "NRC")

# Correlation Matrix
cor(Sentiments)

```

```{block, box.title = "Exercise 4", box.body = list(fill = "white"), box.icon = "fa-star"}
Standardize the comment sentiments for the `syuzhet` method with respect to the total number of words in the respective comment. Call this new Variable `SentimentPerWord`.

```

```{block, opts.label = "clues"}
Computing the number of words requires multiple functions if you want to use base R. The `strplit()` command splits a character string into multiple strings upon a specific indicator, for example a space (" "), the `unlist()` command transfers a list of values into a regular vector. The `length()` function counts the number of elements in a vector and with the `sapply()` function, you can apply a general function to each element of a vector. With these tools, you can compute the number of words per comment.

```

```{r, results = 'hide', solution = TRUE, warning=F, message=F}
# computing number of Words
Words <- sapply(comments$TextEmojiDeleted,function(x){length(unlist(strsplit(x," ")))})

# computing average sentiment per word
SentimentPerWord <- BasicSentimentSyu/Words

```


```{block, box.title = "Exercise 5", box.body = list(fill = "white"), box.icon = "fa-star"}
Compute comment sentiments using the `sentimentr` package. Compare the average comment sentiment per word from the `sentimentr` package with the one we computed. Which one do you think is more trustworthy and why?

```

```{block, opts.label = "clues"}
For a total sentiment score per comment, you first have to use the `get_sentences()` function and then use the `sentiment_by()` function on the sentences. To plot the two different scorings against each other, you need to put them into the same dataframe with `cbind.data.frame()` first. You can then use the `ggplot()` package for plotting.

```

```{r, solution = TRUE, warning=F, message=F}
# computing sentiment scores
Sentences <- get_sentences(comments$TextEmojiDeleted)
SentDF <- sentiment_by(Sentences)

# show output
SentDF[1:3,c(2,3,4)]

# Attaching ave_sentiment to comments dataframe
comments <- cbind.data.frame(comments,ave_sentiment = SentDF$ave_sentiment)

# plotting SentimentPerWord vs. SentimentR
library(ggplot2)
ggplot(comments, aes(x=ave_sentiment, y=SentimentPerWord)) + 
    geom_point(size =0.5) +
    ggtitle("Basic Sentiment Scores vs. `SentimentR`") +
    xlab("SentimentR Score") +
    ylab("Syuzhet Score") +
    geom_smooth(method=lm, se = TRUE)

```

```{block, solution = TRUE}
`SentimentR` is:
  - better at dealing with negations
  - better at detecting fixed expressions
  - better at detecting adverbs
  - better at detecting slang and abbreviations
```


```{block, box.title = "Exercise 6", box.body = list(fill = "white"), box.icon = "fa-star"}
Load the emoji dictionary from the `lexicon` package and copy it to a new dataframe callend `EmojiSentiments`. Change the formatting of the dictionary entries and/or our Emoji column so that they are in the same format and can be matched. You can use the name `EmojiToks` for an intermediary variable if you need to create one. Afterwards, transform the `EmojiSentiment` dataframe to a `quanteda` dictionary object with the `as.dictionary()` function. Finally, use the `tokens_lookup()` function to create a new variable for emoji sentiments called `EmojiToksSent`
```

```{block, opts.label = "clues"}
To see lexicons from the lexicon package, you can run `lexicon::available_data()` to get an overview of all the available lexicons. The name of the emoji lexicon is "emojis_sentiment". Lexicons can be accessed with the command `lexicon::lexicon_name` usng the respective name of the lexicon you want to select. You can use the `paste0()` and `gsub()` functions to bring the formatting of the emoji column in line with the dictionary. Keep in mind that a valid dictionary needs appropriate column names, you can look this up in the help section of the `as.dictionary()` function.

```

```{r, solution = TRUE, warning=F, message=F}
# attaching packages
library(quanteda)
library(qdapRegex)

# emoji Sentiments
EmojiSentiments <- lexicon::emojis_sentiment
EmojiSentiments[1:5,c(1,2,4)]

# changing formatting in dictionary
EmojiNames <- paste0("emoji_",gsub(" ","",EmojiSentiments$name))
EmojiSentiment <- cbind.data.frame(EmojiNames,
                                   EmojiSentiments$sentiment,
                                   EmojiSentiments$polarity)
# naming
names(EmojiSentiment) <- c("word","sentiment","valence")

# see results
EmojiSentiment[1:5,]

# we then tokenize the emoji-only column in our formatted dataframe
EmojiToks <- tokens(tolower(as.character(unlist(comments$Emoji))))
EmojiToks[130:131]

# Creating dictionary object
EmojiSentDict <- as.dictionary(EmojiSentiment[,1:2])

# Replacing Emoji with sentiment scores
EmojiToksSent <- tokens_lookup(x = EmojiToks,
                               dictionary = EmojiSentDict)
EmojiToksSent[130:131]

```


```{block, box.title = "Exercise 7", box.body = list(fill = "white"), box.icon = "fa-star"}
Plot the distribution of `EmojiToksSent`

```

```{block, opts.label = "clues"}
You can use the simple `hist()` function to create a histogram. Keep in mind though that you need to transform the tokens object back to a regular numeric vector. You can do this with the `unlist()` and `as.numeric()` functions.

```

```{r, results = 'hide', solution = TRUE, warning=F, message=F}
hist(as.numeric(unlist(EmojiToksSent)),
     main = "Distribution of Emoji Sentiment",
     xlab = "Emoji Sentiment")

```
